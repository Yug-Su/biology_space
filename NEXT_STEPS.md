# üöÄ Prochaines √âtapes - √âvolution du Projet

## ‚úÖ Ce qui fonctionne maintenant

- ‚úÖ Cl√© OpenRouter configur√©e
- ‚úÖ 572 articles index√©s
- ‚úÖ Interface compl√®te
- ‚úÖ Recherche simple fonctionnelle

---

## üìã √âtapes Prioritaires

### 1Ô∏è‚É£ **Cr√©er le Compte Admin** (5 min)

```bash
cd C:\Users\iamfe\thebox\007
.\venv\Scripts\activate
python manage.py createsuperuser
```

Puis acc√©der √† : http://localhost:8000/admin

---

### 2Ô∏è‚É£ **G√©n√©rer les Embeddings** (10 min, ~$0.50)

```bash
python manage.py generate_embeddings
```

**Active :**
- Recherche s√©mantique IA
- Recommandations d'articles similaires
- Meilleur contexte pour g√©n√©ration

---

### 3Ô∏è‚É£ **Tester les Fonctionnalit√©s IA** (15 min)

#### Chat AI
- URL : http://localhost:8000/chat
- Test : "What are the effects of microgravity on bone density?"

#### G√©n√©rateur d'Articles
- URL : http://localhost:8000/generate
- Topic : "Muscle atrophy in spaceflight"
- Type : Review, Medium, Academic

#### R√©sum√©s IA
- Aller sur un article
- Cliquer "Generate AI Summary"

---

## üõ†Ô∏è Am√©liorations Possibles

### A. **Scraper le Contenu Complet** (3-4h)

Actuellement : Juste titre + URL
Am√©lioration : Extraire abstract + contenu complet

**Fichier √† cr√©er :** `core/management/commands/scrape_articles.py`

```python
from bs4 import BeautifulSoup
import requests

# Scraper les abstracts depuis PubMed Central
for article in Article.objects.filter(abstract__isnull=True):
    response = requests.get(article.url)
    soup = BeautifulSoup(response.text, 'html.parser')

    # Extraire abstract
    abstract = soup.find('div', class_='abstract')
    if abstract:
        article.abstract = abstract.get_text()
        article.save()
```

**Commande :**
```bash
python manage.py scrape_articles
```

---

### B. **Extraction Automatique de Keywords** (2h)

Utiliser l'IA pour extraire mots-cl√©s :

**Fichier :** `core/services/keyword_extractor.py`

```python
async def extract_keywords(text: str) -> list:
    prompt = f"""Extract 5-10 key scientific terms from this text:

    {text[:1000]}

    Return only the keywords, comma-separated."""

    response = await ai_provider.generate(prompt, max_tokens=100)
    return [k.strip() for k in response.split(',')]
```

**Utilisation :**
```python
# Dans admin ou management command
keywords = await extract_keywords(article.title + article.abstract)
article.keywords = keywords
article.save()
```

---

### C. **Visualisations D3.js** (4-5h)

#### 1. Graphe de Connaissances

**Fichier :** `core/templates/core/knowledge_graph.html`

```html
<script src="https://d3js.org/d3.v7.min.js"></script>
<div id="graph"></div>

<script>
// Cr√©er graphe avec articles comme n≈ìuds
// Liens = similarit√© s√©mantique
const data = {{ graph_data|safe }};
// Code D3.js pour visualisation
</script>
```

**View :**
```python
def knowledge_graph(request):
    # Calculer similarit√©s entre articles
    # Cr√©er JSON pour D3.js
    return render(request, 'core/knowledge_graph.html', {
        'graph_data': json.dumps(graph_data)
    })
```

#### 2. Timeline des Publications

```javascript
// Graphique temporel des publications
d3.timeParse("%Y-%m-%d")
// Afficher tendances par ann√©e
```

---

### D. **Export PDF des Articles G√©n√©r√©s** (2h)

**Installation :**
```bash
pip install reportlab
```

**Fichier :** `core/services/pdf_export.py`

```python
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas

def export_to_pdf(article):
    pdf = canvas.Canvas(f"generated_{article.id}.pdf", pagesize=letter)
    pdf.drawString(100, 750, article.title)
    # Formater contenu
    pdf.save()
    return pdf
```

---

### E. **Syst√®me de Citations** (3h)

G√©n√©rer citations automatiques :

```python
def generate_citation(article, style='apa'):
    """Generate citation in APA, MLA, or Chicago style"""
    if style == 'apa':
        return f"{', '.join(article.authors[:3])} ({article.publication_date.year}). {article.title}. {article.pmc_id}"
```

---

### F. **Cache Redis pour Performance** (2h)

```bash
pip install django-redis
```

**settings.py :**
```python
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://127.0.0.1:6379/1',
    }
}
```

**Usage :**
```python
from django.core.cache import cache

@cache_page(60 * 15)  # Cache 15 min
def search(request):
    # ...
```

---

### G. **Tests Automatis√©s** (3-4h)

**Fichier :** `core/tests.py`

```python
from django.test import TestCase

class SearchTestCase(TestCase):
    def test_simple_search(self):
        response = self.client.get('/search/?q=microgravity')
        self.assertEqual(response.status_code, 200)

    def test_ai_chat(self):
        response = self.client.post('/api/chat/message/', {
            'message': 'Test question',
            'session_id': 'test-session'
        })
        self.assertEqual(response.status_code, 200)
```

**Lancer :**
```bash
python manage.py test
```

---

### H. **D√©ploiement Production** (4-6h)

#### Option 1 : Vercel (Frontend + Serverless)

```bash
pip install vercel
vercel init
vercel deploy
```

#### Option 2 : Railway (Backend complet)

1. Cr√©er compte Railway
2. Connecter repo GitHub
3. D√©ployer automatiquement

#### Option 3 : PythonAnywhere (Gratuit)

1. Upload code
2. Configurer WSGI
3. Lancer

**Fichier requis :** `requirements-prod.txt`
```
Django==5.0.1
gunicorn==21.2.0
whitenoise==6.6.0
psycopg2-binary==2.9.9  # Si PostgreSQL
```

---

## üìä Roadmap Sugg√©r√©

### Phase 1 : MVP Complet (Maintenant)
- ‚úÖ Setup et config
- ‚úÖ Fonctionnalit√©s de base
- [ ] Cr√©er superuser
- [ ] G√©n√©rer embeddings
- [ ] Tester IA

### Phase 2 : Am√©lioration Donn√©es (1-2 jours)
- [ ] Scraper abstracts
- [ ] Extraire keywords IA
- [ ] Enrichir m√©tadonn√©es

### Phase 3 : Visualisations (2-3 jours)
- [ ] Graphe de connaissances D3.js
- [ ] Timeline publications
- [ ] Dashboard analytics avanc√©

### Phase 4 : Production (1 jour)
- [ ] Tests unitaires
- [ ] Optimisation performance
- [ ] D√©ploiement
- [ ] Documentation utilisateur

---

## üéØ Quick Wins (1-2h chacun)

1. **Ajouter un logo** :
   - Cr√©er `static/images/logo.png`
   - Mettre dans `base.html`

2. **Th√®me sombre** :
   - Ajouter toggle dark mode avec Alpine.js
   - Stocker pr√©f√©rence dans localStorage

3. **Partage social** :
   - Boutons Twitter/LinkedIn sur articles
   - Open Graph meta tags

4. **Statistiques avanc√©es** :
   - Top auteurs
   - Mots-cl√©s tendances
   - Articles les plus vus

5. **Export donn√©es** :
   - CSV export des recherches
   - JSON export des articles g√©n√©r√©s

---

## üí° Features Innovantes

### 1. **AI Research Assistant Mode**
```python
# Chat qui cite automatiquement les articles
# "According to PMC12345, microgravity causes..."
```

### 2. **Collaborative Research**
```python
# Partager sessions chat
# Annoter articles en √©quipe
```

### 3. **Custom Training**
```python
# Fine-tuner GPT sur le corpus
# R√©ponses encore plus pr√©cises
```

### 4. **Voice Search**
```javascript
// Recherche vocale avec Web Speech API
navigator.mediaDevices.getUserMedia()
```

---

## üîß Code Quality

### Setup pre-commit hooks

```bash
pip install pre-commit black flake8
pre-commit install
```

### `.pre-commit-config.yaml` :
```yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.12.1
    hooks:
      - id: black
  - repo: https://github.com/pycqa/flake8
    rev: 7.0.0
    hooks:
      - id: flake8
```

---

## üìö Ressources Utiles

- **Django Docs** : https://docs.djangoproject.com/
- **OpenRouter Models** : https://openrouter.ai/models
- **D3.js Gallery** : https://observablehq.com/@d3/gallery
- **TailwindCSS** : https://tailwindcss.com/docs

---

**üéØ Commence par les 3 √©tapes prioritaires, puis choisis les am√©liorations selon tes besoins !**
